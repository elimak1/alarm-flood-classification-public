{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import methods.assam as assam\n",
    "import methods.gmm as gmm\n",
    "import methods.hmm as hmm\n",
    "import methods.lstm as lstm\n",
    "import methods.nw as nw\n",
    "import methods.svm as svm\n",
    "import methods.sw as sw\n",
    "import methods.tfidf_lr as tfidf_lr\n",
    "import methods.word2vec as word2vec\n",
    "from methods.evaluate import print_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"CSD\"\n",
    "X_train = pd.read_csv(f\"../data/preprocessed/{system}_train.csv\", index_col=0)\n",
    "X_test = pd.read_csv(f\"../data/preprocessed/{system}_test.csv\", index_col=0)\n",
    "Y_train = pd.read_csv(f\"../data/ground_truth/{system}_train_labels.csv\", index_col=0)\n",
    "Y_train = Y_train.iloc[:,0]\n",
    "Y_test = pd.read_csv(f\"../data/ground_truth/{system}_test_labels.csv\", index_col=0)\n",
    "Y_test = Y_test.iloc[:,0]\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "\n",
    "vocab = {alarm: i for i, alarm in enumerate(X[\"alarmNumber\"].unique())} \n",
    "n_classes = Y_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unkown samples not used in training data (marked as -1)\n",
    "Y_train = Y_train[Y_train != -1]\n",
    "X_train = X_train[X_train[\"flood_id\"].isin(Y_train.index)]\n",
    "n_classes = Y_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip if multiRocket is not setup\n",
    "import methods.castle as castle\n",
    "castle_model = castle.CASTLE_Classifier(vocab)\n",
    "castle_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = castle_model.predict(X_test)\n",
    "print(\"CASTLE metrics\")\n",
    "print_metrics(predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assam_model = assam.ASSAM_Classifier(vocab)\n",
    "assam_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assam_predictions = assam_model.predict(X_test)\n",
    "print(\"Assam metrics\")\n",
    "print_metrics(assam_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_model = gmm.GMM_Classifier(vocab)\n",
    "gmm_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_predictions = gmm_model.predict(X_test)\n",
    "print(\"GMM metrics\")\n",
    "print_metrics(gmm_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_model = hmm.HMM_Classifier(vocab)\n",
    "hmm_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_predictions = hmm_model.predict(X_test)\n",
    "print(\"HMM metrics\")\n",
    "print_metrics(hmm_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = lstm.LSTM_Classifier(vocab,19, embedding_dim=40,slen=51)\n",
    "lstm_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "print(\"LSTM metrics\")\n",
    "print_metrics(lstm_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_model = nw.NW_Classifier(vocab)\n",
    "nw_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_predictions = nw_model.predict(X_test)\n",
    "print(\"Needleman-Wunsch metrics\")\n",
    "print_metrics(nw_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra stuff\n",
    "nw_model.plot_distinquishability()\n",
    "print(\"Not significant alarms\")\n",
    "print(nw_model.non_significant_alarms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVM_Classifier(vocab, max_lag=1)\n",
    "svm_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm_model.predict(X_test)\n",
    "print(\"SVM metrics\")\n",
    "print_metrics(svm_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_model = sw.SW_Classifier(vocab)\n",
    "sw_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_predictions = sw_model.predict(X_test)\n",
    "print(\"Smith-Waterman metrics\")\n",
    "print_metrics(sw_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lr_model = tfidf_lr.TFIDF_LR_Classifier(vocab, use_confidence_thresholds=False)\n",
    "tfidf_lr_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lr_predictions = tfidf_lr_model.predict(X_test)\n",
    "print(\"TFIDF-LR metrics\")\n",
    "print_metrics(tfidf_lr_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model can use categories to improve word embeddings\n",
    "# Create a mapping from alarm embedding to device\n",
    "device_mapping = np.zeros((len(vocab)))\n",
    "for i, row in X.iterrows():\n",
    "    # Remove prefix\n",
    "    alarm = str(row[\"alarmNumber\"])\n",
    "    d = alarm.split(\"_\")[0]\n",
    "    if d == \"System Device\":\n",
    "        device_mapping[vocab[alarm]] = 0\n",
    "    elif d == \"Crane\":\n",
    "        device_mapping[vocab[alarm]] = 1\n",
    "    elif \"MC\" in d:\n",
    "        device_mapping[vocab[alarm]] = 2\n",
    "    elif \"L\" in d:\n",
    "        device_mapping[vocab[alarm]] = 3\n",
    "    elif \"M\" in d:\n",
    "        device_mapping[vocab[alarm]] = 4\n",
    "    else:\n",
    "        device_mapping[vocab[alarm]] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More categories can be created for alarms\n",
    "# This example only used device categories but things such as alarm priority or type of process variable tracked can be used\n",
    "\n",
    "word2vec_model = word2vec.Word2Vec_Classifier(vocab)\n",
    "word2vec_model.fit(X_train, Y_train, 50, [device_mapping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_predictions = word2vec_model.predict(X_test)\n",
    "print(\"Word2Vec metrics\")\n",
    "print_metrics(word2vec_predictions, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model.plot_embeddings(np.arange(0,20))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from remove_chattering import remove_nuisance_alarms \n",
    "from openpyxl.styles import Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook creates a excel representation of alarm floods usefull for manual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alarms = pd.read_csv(f'../../data/CSD_similar_alarms_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_floods = pd.read_csv(f'../../data/CSD_alarm_floods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToKeep = [\"systemId\", \"deviceId\", \"alarmNumber\", \"level\",\"description\",\"startTimestamp\", \"endTimestamp\"]\n",
    "alarms = alarms[columnsToKeep]\n",
    "alarms[\"startTimestamp\"] = pd.to_datetime(alarms[\"startTimestamp\"], errors='coerce')\n",
    "alarms[\"endTimestamp\"] = pd.to_datetime(alarms[\"endTimestamp\"], errors='coerce')\n",
    "alarms = alarms.dropna(subset=[\"startTimestamp\", \"endTimestamp\"])\n",
    "alarms = alarms.sort_values(by=\"startTimestamp\")\n",
    "    \n",
    "device_floods[\"startTimestamp\"] = pd.to_datetime(device_floods[\"startTimestamp\"], errors='coerce')\n",
    "device_floods[\"endTimestamp\"] = pd.to_datetime(device_floods[\"endTimestamp\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crane_floods = device_floods[device_floods[\"deviceId\"].str.contains(\"Crane\")].reset_index()\n",
    "system_groupd = alarms.groupby(\"systemId\")\n",
    "useless_alarms = []\n",
    "messages = [\"Message\"]\n",
    "messages_to_keep = []\n",
    "\n",
    "floods_to_label_df = pd.DataFrame()\n",
    "for i, row in crane_floods.iterrows():\n",
    "    systemId = row[\"deviceId\"].split(\"_\")[0]\n",
    "    system_alarms = system_groupd.get_group(systemId)\n",
    "\n",
    "    alarm_flood_alarms = system_alarms[(system_alarms[\"startTimestamp\"] >= row[\"startTimestamp\"]) & (system_alarms[\"startTimestamp\"] <= row[\"endTimestamp\"])]\n",
    "    if len(alarm_flood_alarms) < 3:\n",
    "        print(systemId, row[\"startTimestamp\"], row[\"endTimestamp\"])\n",
    "    alarm_flood_alarms[\"flood_id\"] = i\n",
    "    floods_to_label_df = pd.concat((floods_to_label_df, alarm_flood_alarms))\n",
    "\n",
    "floods_to_label_df[\"deviceId\"] = floods_to_label_df[\"deviceId\"] + \"_\" + floods_to_label_df[\"flood_id\"].map(str)\n",
    "floods_to_label_df =  remove_nuisance_alarms(floods_to_label_df, 10, messages, useless_alarms)\n",
    "floods_to_label_df = floods_to_label_df.set_index(\"flood_id\")\n",
    "floods_to_label_df[\"startTimestamp\"] = floods_to_label_df[\"startTimestamp\"].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f%z\").str[:-8]\n",
    "floods_to_label_df[\"endTimestamp\"] = floods_to_label_df[\"endTimestamp\"].dt.strftime(\"%Y-%m-%d %H:%M:%S.%f%z\").str[:-8]\n",
    "df = floods_to_label_df.reset_index()\n",
    "df = df[[\"flood_id\", \"deviceId\", \"alarmNumber\", \"startTimestamp\", \"endTimestamp\", \"level\", \"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional initial clusters created with some clustering algorithm to help manual labeling\n",
    "preclustering_labels = pd.read_csv(\"../../data/clusters/CSD_rule_labels.csv\", index_col=\"flood_id\", squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case some initial separation is done by hand and the data is read from the separate files\n",
    "# Defined in the pre_clusters list\n",
    "pre_clusters = []\n",
    "pre_cluster_dict = {}\n",
    "for cluster in pre_clusters:\n",
    "    pre_cluster_dict[cluster] = pd.read_csv(f\"\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"flood_id\"].map(preclustering_labels)\n",
    "def add_label(group):\n",
    "    flood_id_to_label = { flood_id: pre_cluster_dict[group.name].iloc[i][0] for i, flood_id in enumerate(sorted(group[\"flood_id\"].unique())) }\n",
    "    group[\"cluster\"] = group[\"flood_id\"].map(flood_id_to_label)\n",
    "    return group\n",
    "\n",
    "\n",
    "df = df.groupby(\"label\").apply(add_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mc_clusters = df.sort_values(by=[\"label\",\"cluster\", \"flood_id\", \"startTimestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read additional process information usefull for manual labeling\n",
    "statusesDict ={}\n",
    "systems = [] # List of systemIds\n",
    "for systemId in systems:\n",
    "    for device in [\"Crane\", \"System Device\"]:\n",
    "        deviceId = f\"{systemId}_{device}\"\n",
    "        stat_df = pd.read_csv(f\"../../data/CSD_statuses/statuses_{deviceId}.csv\")\n",
    "        stat_df[\"timestamp\"] = pd.to_datetime(stat_df[\"timestamp\"], errors='coerce')\n",
    "        stat_df = stat_df.sort_values(by=\"timestamp\")\n",
    "        stat_df[\"timestamp\"] = stat_df[\"timestamp\"].dt.tz_localize(None)\n",
    "        statusesDict[f\"{systemId}_{device}\"] = stat_df\n",
    "        stat_df = stat_df.sort_values(by=\"timestamp\")\n",
    "        statusesDict[f\"{systemId}_{device}\"] = stat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional process info to help manual labeling\n",
    "def attach_device_status(alarm_row):\n",
    "    id = \"_\".join(alarm_row[\"deviceId\"].split(\"_\")[:-1])\n",
    "    device_status_df = statusesDict[id]\n",
    "    alarm_ts = pd.Timestamp(alarm_row[\"startTimestamp\"])\n",
    "    prev_statuses = device_status_df[(device_status_df[\"timestamp\"] < alarm_ts) & (device_status_df[\"timestamp\"] > alarm_ts - pd.Timedelta(seconds=300))]\n",
    "    if len(prev_statuses) == 0:\n",
    "        try:\n",
    "            prev_statuses = device_status_df[(device_status_df[\"timestamp\"] < alarm_ts)].iloc[-1]\n",
    "            alarm_row[\"device_status\"] = prev_statuses[\"status\"]\n",
    "            return alarm_row\n",
    "        except:\n",
    "            alarm_row[\"device_status\"] = \"No data\"\n",
    "            return alarm_row\n",
    "    status_durations = defaultdict(int)\n",
    "    status_durations[prev_statuses.iloc[0][\"previousStatus\"]] += (prev_statuses.iloc[0][\"timestamp\"]- alarm_ts + pd.Timedelta(seconds=300)).total_seconds()\n",
    "    for i in range(len(prev_statuses)-1):\n",
    "        status_durations[prev_statuses.iloc[i][\"status\"]] += (prev_statuses.iloc[i+1][\"timestamp\"] - prev_statuses.iloc[i][\"timestamp\"]).total_seconds()\n",
    "    status_durations[prev_statuses.iloc[-1][\"status\"]] += (alarm_ts - prev_statuses.iloc[-1][\"timestamp\"]).total_seconds()\n",
    "\n",
    "    most_common_status = max(status_durations, key=status_durations.get)\n",
    "    alarm_row[\"device_status\"] = most_common_status\n",
    "    return alarm_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clusters = sorted_mc_clusters.apply(attach_device_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clusters[(final_clusters[\"flood_id\"] > 239) & (final_clusters[\"flood_id\"] < 248)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f\"../../data/classification/clustered_CSD_alarm_floods.xlsx\", engine='openpyxl') as writer:\n",
    "    for name, g in final_clusters.groupby(\"label\"):\n",
    "        name = name.replace(\"Crane\", \"C\").replace(\"System Device\", \"SD\")[:30]\n",
    "        new = pd.DataFrame()\n",
    "        prev_flood_id = None\n",
    "        for i, row in g.iterrows():\n",
    "            if row[\"flood_id\"] != prev_flood_id and prev_flood_id is not None:\n",
    "                root_cause_row = pd.Series([\"Root cause:\"] + [pd.NA] * (len(sorted_mc_clusters.columns) - 1), index=sorted_mc_clusters.columns)\n",
    "                new = new.append(root_cause_row, ignore_index=True)\n",
    "                new = new.append(row, ignore_index=True)\n",
    "            else:\n",
    "                new = new.append(row, ignore_index=True)\n",
    "            prev_flood_id = row[\"flood_id\"]\n",
    "        df = new[[\"cluster\", \"flood_id\", \"deviceId\", \"alarmNumber\", \"startTimestamp\", \"endTimestamp\", \"level\", \"device_status\", \"description\"]]\n",
    "        df.to_excel(writer, index=False, sheet_name=name)\n",
    "\n",
    "        # Get the xlsxwriter workbook and worksheet objects\n",
    "        workbook  = writer.book\n",
    "        worksheet = writer.sheets[name]\n",
    "\n",
    "        \n",
    "        marker_font = Font(bold=True, color=\"FF0000\")\n",
    "\n",
    "        # Set column widths\n",
    "        worksheet.column_dimensions['A'].width = 9\n",
    "        worksheet.column_dimensions['B'].width = 15\n",
    "        worksheet.column_dimensions['C'].width = 14\n",
    "        worksheet.column_dimensions['D'].width = 13\n",
    "        worksheet.column_dimensions['E'].width = 21\n",
    "        worksheet.column_dimensions['F'].width = 21\n",
    "        worksheet.column_dimensions['G'].width = 12\n",
    "        worksheet.column_dimensions['H'].width = 12\n",
    "        worksheet.column_dimensions['I'].width = 12\n",
    "        worksheet.column_dimensions['J'].width = 12\n",
    "\n",
    "            # Format root cause rows\n",
    "        for row in range(df.shape[0]):\n",
    "            if df.iloc[row]['flood_id'] == 'Root cause:':\n",
    "                for col in range(1, df.shape[1]+1):  # 1-indexed for openpyxl\n",
    "                    worksheet.cell(row=row+2, column=col).font = marker_font  # +2 to account for 1-indexing and header row\n",
    "                    worksheet.row_dimensions[row+2].height = 50\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
